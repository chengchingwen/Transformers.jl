<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>HuggingFace · Transformers.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://chengchingwen.github.io/Transformers.jl/huggingface/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="Transformers.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Transformers.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getstarted/">Get Started</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../layers/">Layers</a></li><li><a class="tocitem" href="../textencoders/">TextEncoders</a></li><li class="is-active"><a class="tocitem" href>HuggingFace</a><ul class="internal"><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li><li><a class="tocitem" href="../changelog/">ChangeLogs</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>HuggingFace</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>HuggingFace</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/chengchingwen/Transformers.jl/blob/master/docs/src/huggingface.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Transformers.HuggingFace"><a class="docs-heading-anchor" href="#Transformers.HuggingFace">Transformers.HuggingFace</a><a id="Transformers.HuggingFace-1"></a><a class="docs-heading-anchor-permalink" href="#Transformers.HuggingFace" title="Permalink"></a></h1><p>Module for loading pre-trained model from HuggingFace.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>We provide a set of API to download &amp; load a pretrain model from huggingface hub. This is mostly manually done, so we  only have a small set of available models. The most practical way to check if a model is available in Transformers  is to run the <a href="https://github.com/chengchingwen/Transformers.jl/tree/master/example/HuggingFaceValidation"><code>HuggingFaceValidation</code> code in the example folder</a>,  which use <code>PyCall.jl</code> to load the model in both Python and Julia. Open issues/PRs if you find a model you want is  not supported here.</p></div></div><p>There are basically 3 main api for loading the model, <a href="#Transformers.HuggingFace.load_config-Tuple{Any}"><code>HuggingFace.load_config</code></a>, <a href="#Transformers.HuggingFace.load_tokenizer"><code>HuggingFace.load_tokenizer</code></a>, <a href="#Transformers.HuggingFace.load_model"><code>HuggingFace.load_model</code></a>. These are the underlying function of the <a href="#Transformers.HuggingFace.@hgf_str-Tuple{Any}"><code>HuggingFace.@hgf_str</code></a> macro. You can get a better control of the loading process.</p><p>We can load a specific config of a specific model, no matter it&#39;s actually supported by Transformers.jl.</p><pre><code class="language-julia-repl hljs">julia&gt; load_config(&quot;google/pegasus-xsum&quot;)
Transformers.HuggingFace.HGFConfig{:pegasus, JSON3.Object{Vector{UInt8}, Vector{UInt64}}, Dict{Symbol, Any}} with 45 entries:
  :use_cache                       =&gt; true
  :d_model                         =&gt; 1024
  :scale_embedding                 =&gt; true
  :add_bias_logits                 =&gt; false
  :static_position_embeddings      =&gt; true
  :encoder_attention_heads         =&gt; 16
  :num_hidden_layers               =&gt; 16
  :encoder_layerdrop               =&gt; 0
  :num_beams                       =&gt; 8
  :max_position_embeddings         =&gt; 512
  :model_type                      =&gt; &quot;pegasus&quot;
  ⋮                                =&gt; ⋮
</code></pre><p>This would give you all value available in the downloaded configuration file. This might be enough for a some model,  but there are other model that use the default value hard coded in their python code.</p><p>Sometime you would want to add/overwrite  some of the value. This can be done be calling <code>HGFConfig(old_config; key_to_update = new_value, ...)</code>. These is used  primary for customizing model loading. For example, you can load a <code>bert-base-cased</code> model for sequence classification  task. However, if you directly load the model:</p><pre><code class="language-julia-repl hljs">julia&gt; bert_model = hgf&quot;bert-base-cased:ForSequenceClassification&quot;;

julia&gt; bert_model.cls.layer
Dense(W = (768, 2), b = true)</code></pre><p>The model is default creating model for 2 class of label. So you would need to load the config and update the field  about number of labels and create the model with the new config:</p><pre><code class="language-julia-repl hljs">julia&gt; bertcfg = load_config(&quot;bert-base-cased&quot;);

julia&gt; bertcfg.num_labels
2

julia&gt; mycfg = HuggingFace.HGFConfig(bertcfg; num_labels = 3);

julia&gt; mycfg.num_labels
3

julia&gt; _bert_model = load_model(&quot;bert-base-cased&quot;, :ForSequenceClassification; config = mycfg);

julia&gt; _bert_model.cls.layer
Dense(W = (768, 3), b = true)
</code></pre><p>All config field name follow the same name as huggingface, so you might need to read their document for what  is available. However, not every configuration work in Transformers.jl. It&#39;s better to check <a href="https://github.com/chengchingwen/Transformers.jl/tree/master/src/huggingface/implementation">the source  <code>src/huggingface/implementation</code></a>. All supported models would need to overload the <code>load_model</code> and provided an implementation in Julia to be  workable.</p><p>For the tokenizer, <code>load_tokenizer</code> is basically the same as calling with <code>@hgf_str</code>. Currently providing customized  config doesn&#39;t change much stuff. The tokenizer might also work for unsupported model because some serialize the whole  tokenizer object, but not every model does that or they use something not covered by our implementation.</p><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.@hgf_str-Tuple{Any}" href="#Transformers.HuggingFace.@hgf_str-Tuple{Any}"><code>Transformers.HuggingFace.@hgf_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">`hgf&quot;&lt;model-name&gt;:&lt;item&gt;&quot;`</code></pre><p>Get <code>item</code> from <code>model-name</code>. This will ensure the required data are downloaded. <code>item</code> can be &quot;config&quot;,  &quot;tokenizer&quot;, and model related like &quot;Model&quot;, or &quot;ForMaskedLM&quot;, etc. Use <a href="#Transformers.HuggingFace.get_model_type"><code>get_model_type</code></a> to see what  model/task are supported. If <code>item</code> is omitted, return a <code>Tuple</code> of <code>&lt;model-name&gt;:tokenizer</code> and <code>&lt;model-name&gt;:model</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/HuggingFace.jl#L22-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.HGFConfig" href="#Transformers.HuggingFace.HGFConfig"><code>Transformers.HuggingFace.HGFConfig</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HGFConfig{model_type}</code></pre><p>The type for holding the configuration for huggingface model <code>model_type</code>.</p><pre><code class="nohighlight hljs">HGFConfig(base_cfg::HGFConfig; kwargs...)</code></pre><p>Return a new <code>HGFConfig</code> object for the same <code>model_type</code> with fields updated with <code>kwargs</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; bertcfg = load_config(&quot;bert-base-cased&quot;);

julia&gt; bertcfg.num_labels
2

julia&gt; mycfg = HuggingFace.HGFConfig(bertcfg; num_labels = 3);

julia&gt; mycfg.num_labels
3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/configs/config.jl#L80-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.get_model_type" href="#Transformers.HuggingFace.get_model_type"><code>Transformers.HuggingFace.get_model_type</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>get_model_type(model_type)</code></p><p>See the list of supported model type of given model. For example, use <code>get_mdoel_type(:gpt2)</code> to see all model/task  that <code>gpt2</code> support. The <code>keys</code> of the returned <code>NamedTuple</code> are all possible task which can be used in  <a href="#Transformers.HuggingFace.load_model"><code>load_model</code></a> or <a href="#Transformers.HuggingFace.@hgf_str-Tuple{Any}"><code>@hgf_str</code></a>.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; HuggingFace.get_model_type(:gpt2)
(model = Transformers.HuggingFace.HGFGPT2Model, lmheadmodel = Transformers.HuggingFace.HGFGPT2LMHeadModel)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/models/models.jl#L9-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.get_state_dict" href="#Transformers.HuggingFace.get_state_dict"><code>Transformers.HuggingFace.get_state_dict</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_state_dict(model)</code></pre><p>Get the state_dict of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/models/models.jl#L141-L145">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_config-Tuple{Any}" href="#Transformers.HuggingFace.load_config-Tuple{Any}"><code>Transformers.HuggingFace.load_config</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_config(model_name; local_files_only = false, cache = true)</code></pre><p>Load the configuration file of <code>model_name</code> from huggingface hub. By default, this function would check if <code>model_name</code>  exists on huggingface hub, download the configuration file (and cache it if <code>cache</code> is set), and then load and return  the config<code>::HGFConfig</code>. If <code>local_files_only = false</code>, it would check whether the configuration file is up-to-date  and update if not (and thus require network access every time it is called). By setting <code>local_files_only = true</code>, it  would try to find the files from the cache directly and error out if not found. For managing the caches, see the  <code>HuggingFaceApi.jl</code> package. This function would require the configuration file has a field about the <code>model_type</code>, if  not, use <code>load_config(model_type, HuggingFace.load_config_dict(model_name; local_files_only, cache))</code> with <code>model_type</code>  manually provided.</p><p>See also: <a href="#Transformers.HuggingFace.HGFConfig"><code>HGFConfig</code></a></p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; load_config(&quot;bert-base-cased&quot;)
Transformers.HuggingFace.HGFConfig{:bert, JSON3.Object{Vector{UInt8}, Vector{UInt64}}, Nothing} with 19 entries:
  :architectures                =&gt; [&quot;BertForMaskedLM&quot;]
  :attention_probs_dropout_prob =&gt; 0.1
  :gradient_checkpointing       =&gt; false
  :hidden_act                   =&gt; &quot;gelu&quot;
  :hidden_dropout_prob          =&gt; 0.1
  :hidden_size                  =&gt; 768
  :initializer_range            =&gt; 0.02
  :intermediate_size            =&gt; 3072
  :layer_norm_eps               =&gt; 1.0e-12
  :max_position_embeddings      =&gt; 512
  :model_type                   =&gt; &quot;bert&quot;
  :num_attention_heads          =&gt; 12
  :num_hidden_layers            =&gt; 12
  :pad_token_id                 =&gt; 0
  :position_embedding_type      =&gt; &quot;absolute&quot;
  :transformers_version         =&gt; &quot;4.6.0.dev0&quot;
  :type_vocab_size              =&gt; 2
  :use_cache                    =&gt; true
  :vocab_size                   =&gt; 28996
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/configs/auto.jl#L1-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_config-Tuple{Union{Symbol, Val}, Any}" href="#Transformers.HuggingFace.load_config-Tuple{Union{Symbol, Val}, Any}"><code>Transformers.HuggingFace.load_config</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_config(model_type, cfg)</code></pre><p>Load <code>cfg</code> as <code>model_type</code>. This is used for manually load a config when <code>model_type</code> is not specified in the config.  <code>model_type</code> is a <code>Symbol</code> of the model type like <code>:bert</code>, <code>:gpt2</code>, <code>:t5</code>, etc.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/configs/auto.jl#L61-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_hgf_pretrained-Tuple{Any}" href="#Transformers.HuggingFace.load_hgf_pretrained-Tuple{Any}"><code>Transformers.HuggingFace.load_hgf_pretrained</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>load_hgf_pretrained(name)</code></p><p>The underlying function of <a href="#Transformers.HuggingFace.@hgf_str-Tuple{Any}"><code>@hgf_str</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/HuggingFace.jl#L33-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_model" href="#Transformers.HuggingFace.load_model"><code>Transformers.HuggingFace.load_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">load_model([model_type::Symbol,] model_name, task = :model [, state_dict];
           trainmode = false, config = nothing, local_files_only = false, cache = true)</code></pre><p>Load the model of <code>model_name</code> for <code>task</code>. This function would load the <code>state_dict</code> of <code>model_name</code> and build a new  model according to <code>config</code>, <code>task</code>, and the <code>state_dict</code>. <code>local_files_only</code> and <code>cache</code> kwargs would be pass directly  to both <a href="#Transformers.HuggingFace.load_state_dict-Tuple{Any}"><code>load_state_dict</code></a> and <a href="#Transformers.HuggingFace.load_config-Tuple{Any}"><code>load_config</code></a> if not provided. This function would require the  configuration file has a field about the <code>model_type</code>, if not, use <code>load_model(model_type, model_name, task; kwargs...)</code>  with <code>model_type</code> manually provided. <code>trainmode = false</code> would disable all dropouts. The <code>state_dict</code> can be directly  provided, this is used when you want to create a new model with the <code>state_dict</code> in hand. Use <a href="#Transformers.HuggingFace.get_model_type"><code>get_model_type</code></a>  to see what <code>task</code> is available.</p><p>See also: <a href="#Transformers.HuggingFace.get_model_type"><code>get_model_type</code></a>, <a href="#Transformers.HuggingFace.load_state_dict-Tuple{Any}"><code>load_state_dict</code></a>, <a href="#Transformers.HuggingFace.load_config-Tuple{Any}"><code>load_config</code></a>, <a href="#Transformers.HuggingFace.HGFConfig"><code>HGFConfig</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/models/models.jl#L125-L138">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_model-Tuple{Type, Any}" href="#Transformers.HuggingFace.load_model-Tuple{Type, Any}"><code>Transformers.HuggingFace.load_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_model(::Type{T}, config, state_dict = OrderedDict())</code></pre><p>Create a new model of <code>T</code> according to <code>config</code> and <code>state_dict</code>. missing parameter would initialized according  to <code>config</code>. Set the <code>JULIA_DEBUG=Transformers</code> environment variable to see what parameters are missing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/models/models.jl#L148-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_state_dict-Tuple{Any}" href="#Transformers.HuggingFace.load_state_dict-Tuple{Any}"><code>Transformers.HuggingFace.load_state_dict</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>load_state_dict(model_name; local_files_only = false, cache = true)</code></p><p>Load the <code>state_dict</code> from the given <code>model_name</code> from huggingface hub. By default, this function would check if  <code>model_name</code> exists on huggingface hub, download the model file (and cache it if <code>cache</code> is set), and then load  and return the <code>state_dict</code>. If <code>local_files_only = false</code>, it would check whether the model file is up-to-date and  update if not (and thus require network access every time it is called). By setting <code>local_files_only = true</code>, it  would try to find the files from the cache directly and error out if not found. For managing the caches, see the  <code>HuggingFaceApi.jl</code> package.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/weight.jl#L5-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.load_tokenizer" href="#Transformers.HuggingFace.load_tokenizer"><code>Transformers.HuggingFace.load_tokenizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">load_tokenizer(model_name; config = nothing, local_files_only = false, cache = true)</code></pre><p>Load the text encoder of <code>model_name</code> from huggingface hub. By default, this function would check if <code>model_name</code>  exists on huggingface hub, download all required files for this text encoder (and cache these files if <code>cache</code> is  set), and then load and return the text encoder. If <code>local_files_only = false</code>, it would check whether all cached  files are up-to-date and update if not (and thus require network access every time it is called). By setting  <code>local_files_only = true</code>, it would try to find the files from the cache directly and error out if not found.  For managing the caches, see the <code>HuggingFaceApi.jl</code> package.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; load_tokenizer(&quot;t5-small&quot;)
T5TextEncoder(
├─ TextTokenizer(MatchTokenization(PrecompiledNormalizer(WordReplaceNormalizer(UnigramTokenization(EachSplitTokenization(splitter = isspace), unigram = Unigram(vocab_size = 32100, unk = &lt;unk&gt;)), pattern = r&quot;^(?!▁)(.*)$&quot; =&gt; s&quot;▁&quot;), precompiled = PrecompiledNorm(...)), 103 patterns)),
├─ vocab = Vocab{String, SizedArray}(size = 32100, unk = &lt;unk&gt;, unki = 3),
├─ endsym = &lt;/s&gt;,
├─ padsym = &lt;pad&gt;,
└─ process = Pipelines:
  ╰─ target[token] := TextEncodeBase.nestedcall(string_getvalue, source)
  ╰─ target[token] := Transformers.TextEncoders.grouping_sentence(target.token)
  ╰─ target[(token, segment)] := SequenceTemplate{String}(Input[1]:&lt;type=1&gt; &lt;/s&gt;:&lt;type=1&gt; (Input[2]:&lt;type=1&gt; &lt;/s&gt;:&lt;type=1&gt;)...)(target.token)
  ╰─ target[attention_mask] := (NeuralAttentionlib.LengthMask ∘ Transformers.TextEncoders.getlengths(nothing))(target.token)
  ╰─ target[token] := TextEncodeBase.trunc_and_pad(nothing, &lt;pad&gt;, tail, tail)(target.token)
  ╰─ target[token] := TextEncodeBase.nested2batch(target.token)
  ╰─ target := (target.token, target.attention_mask)
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/tokenizer/tokenizer.jl#L117-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.save_config-Tuple{Any, Any}" href="#Transformers.HuggingFace.save_config-Tuple{Any, Any}"><code>Transformers.HuggingFace.save_config</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">save_config(model_name, config; path = pwd(), config_name = CONFIG_NAME, force = false)</code></pre><p>Save the <code>config</code> at <code>&lt;path&gt;/&lt;model_name&gt;/&lt;config_name&gt;</code>. This would error out if the file already exists but <code>force</code>  not set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/configs/auto.jl#L78-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.save_model-Tuple{Any, Any}" href="#Transformers.HuggingFace.save_model-Tuple{Any, Any}"><code>Transformers.HuggingFace.save_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>save_model(model_name, model; path = pwd(), weight_name = PYTORCH_WEIGHTS_NAME, force = false)</code></p><p>save the <code>model</code> state<em>dict at `&lt;path&gt;/&lt;model</em>name&gt;/&lt;weight_name&gt;<code>. This would error out if the file already exists  but</code>force` not set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/models/models.jl#L88-L93">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Transformers.HuggingFace.state_dict_to_namedtuple-Tuple{Any}" href="#Transformers.HuggingFace.state_dict_to_namedtuple-Tuple{Any}"><code>Transformers.HuggingFace.state_dict_to_namedtuple</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>state_dict_to_namedtuple(state_dict)</code></p><p>convert state_dict into nested <code>NamedTuple</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/chengchingwen/Transformers.jl/blob/bc7e8d4d27776f347bf4b77823a180a74de2a785/src/huggingface/weight.jl#L29-L33">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../textencoders/">« TextEncoders</a><a class="docs-footer-nextpage" href="../changelog/">ChangeLogs »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 4 August 2023 13:14">Friday 4 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
