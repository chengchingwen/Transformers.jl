<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Transformers.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="Transformers.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Transformers.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation-1"><span>Installation</span></a></li><li><a class="tocitem" href="#Implemented-model-1"><span>Implemented model</span></a></li><li><a class="tocitem" href="#Example-1"><span>Example</span></a></li><li class="toplevel"><a class="tocitem" href="#Module-Hierarchy-1"><span>Module Hierarchy</span></a></li><li><a class="tocitem" href="#Outline-1"><span>Outline</span></a></li></ul></li><li><a class="tocitem" href="tutorial/">Tutorial</a></li><li><a class="tocitem" href="basic/">Basic</a></li><li><a class="tocitem" href="stacks/">Stacks</a></li><li><a class="tocitem" href="pretrain/">Pretrain</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="gpt/">GPT</a></li><li><a class="tocitem" href="bert/">BERT</a></li></ul></li><li><a class="tocitem" href="datasets/">Datasets</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/chengchingwen/Transformers.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Transformers.jl-1"><a class="docs-heading-anchor" href="#Transformers.jl-1">Transformers.jl</a><a class="docs-heading-anchor-permalink" href="#Transformers.jl-1" title="Permalink"></a></h1><p><em>Julia implementation of Transformers models</em></p><p>This is the documentation of <code>Transformers</code>: The Julia solution for using Transformer models based on <a href="https://fluxml.ai/">Flux.jl</a></p><h2 id="Installation-1"><a class="docs-heading-anchor" href="#Installation-1">Installation</a><a class="docs-heading-anchor-permalink" href="#Installation-1" title="Permalink"></a></h2><p>In the Julia REPL:</p><pre><code class="language-jl">julia&gt; ]add Transformers</code></pre><p>For using GPU, make sure <code>CUDA.jl</code> is runable on your computer:</p><pre><code class="language-jl">julia&gt; ]add CUDA; build</code></pre><h2 id="Implemented-model-1"><a class="docs-heading-anchor" href="#Implemented-model-1">Implemented model</a><a class="docs-heading-anchor-permalink" href="#Implemented-model-1" title="Permalink"></a></h2><p>You can find the code in <code>example</code> folder.</p><ul><li><a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a></li><li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li><li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li></ul><h2 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example</a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h2><p>Using pretrained Bert with <code>Transformers.jl</code>.</p><pre><code class="language-julia">using Transformers
using Transformers.Basic
using Transformers.Pretrain

ENV[&quot;DATADEPS_ALWAYS_ACCEPT&quot;] = true

bert_model, wordpiece, tokenizer = pretrain&quot;bert-uncased_L-12_H-768_A-12&quot;
vocab = Vocabulary(wordpiece)

text1 = &quot;Peter Piper picked a peck of pickled peppers&quot; |&gt; tokenizer |&gt; wordpiece
text2 = &quot;Fuzzy Wuzzy was a bear&quot; |&gt; tokenizer |&gt; wordpiece

text = [&quot;[CLS]&quot;; text1; &quot;[SEP]&quot;; text2; &quot;[SEP]&quot;]
@assert text == [
    &quot;[CLS]&quot;, &quot;peter&quot;, &quot;piper&quot;, &quot;picked&quot;, &quot;a&quot;, &quot;peck&quot;, &quot;of&quot;, &quot;pick&quot;, &quot;##led&quot;, &quot;peppers&quot;, &quot;[SEP]&quot;, 
    &quot;fuzzy&quot;, &quot;wu&quot;, &quot;##zzy&quot;,  &quot;was&quot;, &quot;a&quot;, &quot;bear&quot;, &quot;[SEP]&quot;
]

token_indices = vocab(text)
segment_indices = [fill(1, length(text1)+2); fill(2, length(text2)+1)]

sample = (tok = token_indices, segment = segment_indices)

bert_embedding = sample |&gt; bert_model.embed
feature_tensors = bert_embedding |&gt; bert_model.transformers</code></pre><h1 id="Module-Hierarchy-1"><a class="docs-heading-anchor" href="#Module-Hierarchy-1">Module Hierarchy</a><a class="docs-heading-anchor-permalink" href="#Module-Hierarchy-1" title="Permalink"></a></h1><ul><li><a href="basic/">Transformers.Basic</a></li></ul><p>Basic functionality of Transformers.jl, provide the Transformer encoder/decoder implementation and other convenient function.</p><ul><li><a href="pretrain/">Transformers.Pretrain</a></li></ul><p>Functions for download and loading pretrain models.</p><ul><li><a href="stacks/">Transformers.Stacks</a></li></ul><p>Helper struct and DSL for stacking functions/layers.</p><ul><li><a href="datasets/">Transformers.Datasets</a></li></ul><p>Functions for loading some common Datasets</p><ul><li><a href="gpt/">Transformers.GenerativePreTrain</a></li></ul><p>Implementation of gpt-1 model</p><ul><li><a href="bert/">Transformers.BidirectionalEncoder</a></li></ul><p>Implementation of BERT model</p><h2 id="Outline-1"><a class="docs-heading-anchor" href="#Outline-1">Outline</a><a class="docs-heading-anchor-permalink" href="#Outline-1" title="Permalink"></a></h2><ul><li><a href="tutorial/#Tutorial-1">Tutorial</a></li><ul><li><a href="tutorial/#Transformer-model-1">Transformer model</a></li><ul><li><a href="tutorial/#Multi-Head-Attention-1">Multi-Head Attention</a></li><li><a href="tutorial/#Positional-Embedding-1">Positional Embedding</a></li></ul><li><a href="tutorial/#Transformers.jl-1">Transformers.jl</a></li><ul><li><a href="tutorial/#Example-1">Example</a></li><li><a href="tutorial/#Copy-task-1">Copy task</a></li><li><a href="tutorial/#Defining-the-model-1">Defining the model</a></li><li><a href="tutorial/#define-the-loss-and-training-loop-1">define the loss and training loop</a></li><li><a href="tutorial/#Test-our-model-1">Test our model</a></li></ul></ul><li><a href="basic/#Transformers.Basic-1">Transformers.Basic</a></li><ul><li><a href="basic/#Transformer-1">Transformer</a></li><li><a href="basic/#Positionwise-1">Positionwise</a></li><li><a href="basic/#PositionEmbedding-1">PositionEmbedding</a></li><li><a href="basic/#API-Reference-1">API Reference</a></li></ul><li><a href="stacks/#Transformers.Stacks-1">Transformers.Stacks</a></li><ul><li><a href="stacks/#The-Stack-NNTopo-DSL-1">The Stack NNTopo DSL</a></li><li><a href="stacks/#NNTopo-Syntax-1">NNTopo Syntax</a></li><ul><li><a href="stacks/#&quot;Chain&quot;-the-functions-1">&quot;Chain&quot; the functions</a></li><li><a href="stacks/#Loop-unrolling-1">Loop unrolling</a></li><li><a href="stacks/#Multiple-argument-and-jump-connection-1">Multiple argument &amp; jump connection</a></li><li><a href="stacks/#Specify-the-variables-you-want-1">Specify the variables you want</a></li><li><a href="stacks/#Interpolation-1">Interpolation</a></li><li><a href="stacks/#Nested-Structure-1">Nested Structure</a></li><li><a href="stacks/#Collect-Variables-1">Collect Variables</a></li></ul><li><a href="stacks/#Stack-1">Stack</a></li></ul><li><a href="pretrain/#Transformers.Pretrain-1">Transformers.Pretrain</a></li><ul><li><a href="pretrain/#using-Pretrains-1">using Pretrains</a></li><li><a href="pretrain/#API-reference-1">API reference</a></li></ul><li><a href="gpt/#Transformers.GenerativePreTrain-1">Transformers.GenerativePreTrain</a></li><ul><li><a href="gpt/#API-reference-1">API reference</a></li></ul><li><a href="bert/#Transformers.BidirectionalEncoder-1">Transformers.BidirectionalEncoder</a></li><ul><li><a href="bert/#Get-Pretrain-1">Get Pretrain</a></li><li><a href="bert/#Finetuning-1">Finetuning</a></li><li><a href="bert/#API-reference-1">API reference</a></li></ul><li><a href="datasets/#Transformers.Datasets-(not-complete)-1">Transformers.Datasets (not complete)</a></li><ul><li><a href="datasets/#Provide-datasets-1">Provide datasets</a></li><li><a href="datasets/#example-1">example</a></li><li><a href="datasets/#API-reference-1">API reference</a></li></ul></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorial/">Tutorial »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 30 August 2020 15:20">Sunday 30 August 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
