<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Transformers.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="Transformers.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Transformers.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Implemented-model"><span>Implemented model</span></a></li><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li class="toplevel"><a class="tocitem" href="#Module-Hierarchy"><span>Module Hierarchy</span></a></li><li><a class="tocitem" href="#Outline"><span>Outline</span></a></li></ul></li><li><a class="tocitem" href="tutorial/">Tutorial</a></li><li><a class="tocitem" href="basic/">Basic</a></li><li><a class="tocitem" href="stacks/">Stacks</a></li><li><a class="tocitem" href="pretrain/">Pretrain</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="gpt/">GPT</a></li><li><a class="tocitem" href="bert/">BERT</a></li></ul></li><li><a class="tocitem" href="datasets/">Datasets</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/chengchingwen/Transformers.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Transformers.jl"><a class="docs-heading-anchor" href="#Transformers.jl">Transformers.jl</a><a id="Transformers.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Transformers.jl" title="Permalink"></a></h1><p><em>Julia implementation of Transformers models</em></p><p>This is the documentation of <code>Transformers</code>: The Julia solution for using Transformer models based on <a href="https://fluxml.ai/">Flux.jl</a></p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>In the Julia REPL:</p><pre><code class="language-jl">julia&gt; ]add Transformers</code></pre><p>For using GPU, make sure <code>CUDA.jl</code> is runable on your computer:</p><pre><code class="language-jl">julia&gt; ]add CUDA; build</code></pre><h2 id="Implemented-model"><a class="docs-heading-anchor" href="#Implemented-model">Implemented model</a><a id="Implemented-model-1"></a><a class="docs-heading-anchor-permalink" href="#Implemented-model" title="Permalink"></a></h2><p>You can find the code in <code>example</code> folder.</p><ul><li><a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a></li><li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li><li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li></ul><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>Using pretrained Bert with <code>Transformers.jl</code>.</p><pre><code class="language-julia">using Transformers
using Transformers.Basic
using Transformers.Pretrain

ENV[&quot;DATADEPS_ALWAYS_ACCEPT&quot;] = true

bert_model, wordpiece, tokenizer = pretrain&quot;bert-uncased_L-12_H-768_A-12&quot;
vocab = Vocabulary(wordpiece)

text1 = &quot;Peter Piper picked a peck of pickled peppers&quot; |&gt; tokenizer |&gt; wordpiece
text2 = &quot;Fuzzy Wuzzy was a bear&quot; |&gt; tokenizer |&gt; wordpiece

text = [&quot;[CLS]&quot;; text1; &quot;[SEP]&quot;; text2; &quot;[SEP]&quot;]
@assert text == [
    &quot;[CLS]&quot;, &quot;peter&quot;, &quot;piper&quot;, &quot;picked&quot;, &quot;a&quot;, &quot;peck&quot;, &quot;of&quot;, &quot;pick&quot;, &quot;##led&quot;, &quot;peppers&quot;, &quot;[SEP]&quot;, 
    &quot;fuzzy&quot;, &quot;wu&quot;, &quot;##zzy&quot;,  &quot;was&quot;, &quot;a&quot;, &quot;bear&quot;, &quot;[SEP]&quot;
]

token_indices = vocab(text)
segment_indices = [fill(1, length(text1)+2); fill(2, length(text2)+1)]

sample = (tok = token_indices, segment = segment_indices)

bert_embedding = sample |&gt; bert_model.embed
feature_tensors = bert_embedding |&gt; bert_model.transformers</code></pre><h1 id="Module-Hierarchy"><a class="docs-heading-anchor" href="#Module-Hierarchy">Module Hierarchy</a><a id="Module-Hierarchy-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Hierarchy" title="Permalink"></a></h1><ul><li><a href="basic/">Transformers.Basic</a></li></ul><p>Basic functionality of Transformers.jl, provide the Transformer encoder/decoder implementation and other convenient function.</p><ul><li><a href="pretrain/">Transformers.Pretrain</a></li></ul><p>Functions for download and loading pretrain models.</p><ul><li><a href="stacks/">Transformers.Stacks</a></li></ul><p>Helper struct and DSL for stacking functions/layers.</p><ul><li><a href="datasets/">Transformers.Datasets</a></li></ul><p>Functions for loading some common Datasets</p><ul><li><a href="gpt/">Transformers.GenerativePreTrain</a></li></ul><p>Implementation of gpt-1 model</p><ul><li><a href="bert/">Transformers.BidirectionalEncoder</a></li></ul><p>Implementation of BERT model</p><h2 id="Outline"><a class="docs-heading-anchor" href="#Outline">Outline</a><a id="Outline-1"></a><a class="docs-heading-anchor-permalink" href="#Outline" title="Permalink"></a></h2><ul><li><a href="tutorial/#Tutorial">Tutorial</a></li><ul><li><a href="tutorial/#Transformer-model">Transformer model</a></li><ul><li><a href="tutorial/#Multi-Head-Attention">Multi-Head Attention</a></li><li><a href="tutorial/#Positional-Embedding">Positional Embedding</a></li></ul><li><a href="tutorial/#Transformers.jl">Transformers.jl</a></li><ul><li><a href="tutorial/#Example">Example</a></li><li><a href="tutorial/#Copy-task">Copy task</a></li><li><a href="tutorial/#Defining-the-model">Defining the model</a></li><li><a href="tutorial/#define-the-loss-and-training-loop">define the loss and training loop</a></li><li><a href="tutorial/#Test-our-model">Test our model</a></li></ul></ul><li><a href="basic/#Transformers.Basic">Transformers.Basic</a></li><ul><li><a href="basic/#Transformer">Transformer</a></li><li><a href="basic/#Positionwise">Positionwise</a></li><li><a href="basic/#PositionEmbedding">PositionEmbedding</a></li><li><a href="basic/#API-Reference">API Reference</a></li></ul><li><a href="stacks/#Transformers.Stacks">Transformers.Stacks</a></li><ul><li><a href="stacks/#The-Stack-NNTopo-DSL">The Stack NNTopo DSL</a></li><li><a href="stacks/#NNTopo-Syntax">NNTopo Syntax</a></li><ul><li><a href="stacks/#&quot;Chain&quot;-the-functions">&quot;Chain&quot; the functions</a></li><li><a href="stacks/#Loop-unrolling">Loop unrolling</a></li><li><a href="stacks/#Multiple-argument-and-jump-connection">Multiple argument &amp; jump connection</a></li><li><a href="stacks/#Specify-the-variables-you-want">Specify the variables you want</a></li><li><a href="stacks/#Interpolation">Interpolation</a></li><li><a href="stacks/#Nested-Structure">Nested Structure</a></li><li><a href="stacks/#Collect-Variables">Collect Variables</a></li></ul><li><a href="stacks/#Stack">Stack</a></li></ul><li><a href="pretrain/#Transformers.Pretrain">Transformers.Pretrain</a></li><ul><li><a href="pretrain/#using-Pretrains">using Pretrains</a></li><li><a href="pretrain/#API-reference">API reference</a></li></ul><li><a href="gpt/#Transformers.GenerativePreTrain">Transformers.GenerativePreTrain</a></li><ul><li><a href="gpt/#API-reference">API reference</a></li></ul><li><a href="bert/#Transformers.BidirectionalEncoder">Transformers.BidirectionalEncoder</a></li><ul><li><a href="bert/#Get-Pretrain">Get Pretrain</a></li><li><a href="bert/#Finetuning">Finetuning</a></li><li><a href="bert/#API-reference">API reference</a></li></ul><li><a href="datasets/#Transformers.Datasets-(not-complete)">Transformers.Datasets (not complete)</a></li><ul><li><a href="datasets/#Provide-datasets">Provide datasets</a></li><li><a href="datasets/#example">example</a></li><li><a href="datasets/#API-reference">API reference</a></li></ul></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorial/">Tutorial »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 8 April 2021 22:00">Thursday 8 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
